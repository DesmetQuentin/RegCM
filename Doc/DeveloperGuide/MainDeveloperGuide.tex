\chapter{Introduction}


This guide is intended for people interested in developing and enhancing
the \PR package. It describes the \fort programming style used in \PR and
explain the underlying principles of {\em object-based} and module-oriented
programming followed throughout our implementation.  The aim is to help the
developer to understand the general philosophy followed during our project
and easily improve upon the existing code.

\section{About \fort in \PR}

Release \PR differs significantly from the previous ones (versions 3 and
4.0).  The most important change is that the package is undergoing a complete
refactoring to be written in \fort. This will require in the next future a
radical change from the previous \oldfort, a procedural programming language,
to an {\em object-based/oriented} programming protocol.

It is our opinion that \oldfort is no longer the right tool to deal with
such a large project, especially when large type of data sets need to be
managed across the whole package, and the model itself needs a clean and
convenient infrastructure to be coupled with a broad spectrum of complementary
physics models to become part of more complete earth climate modelling
framework. The main weakness of \oldfort is the lack
of any explicit mechanism to express the dependencies among different data
structures and procedures. This makes the development process hard and
difficult: any new change in the code requires an analysis of the involved
data across the whole code and, in the case of \oldfort, this is done
necessarily by analyzing many source files.  This procedure could be very
error prone, especially for developers not mastering all the data of the
entire software project.  \par On the contrary \fort is a modern
programming language with features that support new important programming
concepts, including some of those used in object oriented (OO)
programming. \fort is moreover backward compatible with \oldfort: it was
therefore possible to introduce \fort features into the code in a
incremental fashion, and a lot of work already done could be easily
incorporated.\par
\PR represents now a first release towards a full development along the 
guidelines of modular and OO programming style.  The transition from
procedural to the modular paradigm and later object -base paradigm is not
yet completed in the present release.  At this stage, after having analyzed
the old data structures and their interdependencies, we have built a first
hierarchy of modules containing the relevant data structures. In this way
the relationships amongst data are made explicit. Furthermore in some
cases we have included directly in the module itself the subroutines acting
on the data : this is the concept of classes of methods on OO programming
and now data and routines acting on them are tightly linked
together. Therefore any modification of the code becomes extremely
localized, and adding new features needs a much simpler
intervention than in the past. For example, implementing a new algorithm
for dust requires just to change a single \fort module. \par
To summarize it has to be stressed that now in \fort the building blocks
of the program are modules, not subroutines, and to modify the code one has
to understand the modules hierarchy build up. The general description of
the latter is presented in the following sections.

\section{Object-oriented programming in \fort}


Learning \fort is easy for \oldfort  programmers
\cite{Brainerd,Metcalf,Kerrigan}. A more difficult task is ``thinking'' in
terms of {\em objects} and {\em methods} \cite{Stroustrup}, even though
\fort is not really an object-oriented, but only an object-based, language.\par
There is an excellent web site \cite{oof90_web} where OO techniques used in the \PR project are
clearly explained and examples are provided. We strongly recommend it to
interested  people.


\chapter{The \PR programming style}

The programming style of \PR is intended to be as uniform as possible.
Potential contributors to the code are kindly requested to follow the stylistic convention.

\section{Programming Language}

The general programming language is \fort. 
Some \oldfort routines are still present in the
package and they should be regarded as temporary, and due to migration
from version 3.0.
\C routines are permissible, provided they are Fortran compatible.
File names extensions are:

 \begin{itemize}
 \item 
 \verb=.F90= : for f90 free format code, containing preprocessing directives
  to be analyzed by fortran preprocessor
 \item
 \verb=.f90= : for f90 free format code not to be preprocessed.
 \item
 \verb=.c= : for C code 
 \end{itemize}

Compilation is achieved with a hierarchy of Makefiles
 \begin{itemize}
  \item
    \verb=Makefile= : the Makefile with general and architecture-independent 
                      rules
  \item
    \verb=Makefile.={\it arch} : the architecture dependent Makefiles
  \end{itemize}
Two distinct rules are given in the Makefile:

 \begin{itemize}
 \item
  \verb=.F90.o=  using the macros {\macro \$(F90)} and 
{\macro \$(FCFLAGS)} for related flags. The files are preprocessed.
 \item
  \verb=.f90.o= rule, using the macros {\macro \$(F90)} for compiler and 
{\macro \$(FCFLAGS)} for related flags.
 \end{itemize}

Modules have always the extension \verb=.[fF]90=. and should start with \verb=\mod_=.
Avoid uppercase letters, especially for modules, since module names
are converted to lowercase by the compiler.
 
\subsection{ Banned \oldfort language features:}

 \begin{itemize}
 \item {\tt common}, instead use modules;
 \item {\tt include}, instead use modules and \verb=#include=;
 \item {\tt implicit double precision}, instead use {\tt implicit none});
 \item  Obsolescent \oldfort features, e.g. see Chapt.1 of \cite{Kerrigan}.;
 \item \oldfort notation, such as \verb=real*8=, etc.;
 \item  Non-standard \oldfort integer pointers, instead use allocatable
   arrays, or \fort pointers;
 \item  Avoid vendor extensions that diminish portability.
 \end{itemize}


\section{Target Computers}

\PR is primarily developed on Linux Cluster in both its serial and parallel versions using the MPI communication library. 

During its developing phase the code is compiled using three different suite of compilers:

\begin{itemize}
\item Intel suite compiler (from 10.1 to 12.0 )
\item gfortran compiler  version 4.4 on 
\item Pgi suite of compiler (version 9.03 on) 
\end{itemize}

The code is, however, developed having in mind portability (see later for a detailed
discussion about this issue) and it has also been carefully tested (parallel version) on AIX SP6 IBM platform with xlf  compiler.

\section{Module Template}

A \verb=module= is the basic unit of the code, and any function or subroutine is
wrapped in a \verb=module=. A \verb=module= contains data to be shared with
other \PR modules and data internal to the \verb=module=. The \fort attribute
\verb=private= should be placed right after the \verb=use= lines in the
\verb=module= code. Any items, be data, function or subroutine to be accessed
from other modules or the Main program is to be explicitly given the 
\verb=public= attribute.

Two default subroutines should be present in a \verb=module=:

\begin{enumerate}
\item \verb=init_mod_modname= : Allocates dynamic space in heap and set up any
internal control flag.
\item \verb=release_mod_modname= : Deallocates resources and cleanup
\end{enumerate}

Any number of function and subroutines can be present in a \verb=module=
The variables in the subroutine arguments are specified in the order:

\begin{enumerate}
\item input arguments to subroutine
\item output arguments from subroutine
\item logical flags to control internal branching
\end{enumerate}

This method is sometimes used quite liberally. 
\PR enforces for a safer a cleaner programming usage of the \fort
attribute \verb=intent(in/out/inout)= for subroutine arguments.  
An example of a module with a defined subroutine is given in the following
example:

\lstinputlisting[language=Fortran]{mod_template.f90}

\section{FORTRAN Parameters}
All parameters defined by the \fort parameter statements are specified
in modules and described in one or more comment cards.

\section{Arithmetic Precision}
All real variables and parameters are specified in 64-bit precision 
(i.e. real(kind=8)). 
The future release of \PR will count on \fort features in order to set its
proper defined precision. 

\section{Units}
\PR uses the same internal units of \D ({\it molecular units}). 

\section{Error Messages}

In \verb=mod_services.F90=, there are two subroutines ({\tt error\_prot(),
e\_alloca()}) devoted to error handling. The first is a general purpose
routine that allow printing of messages of different levels of
verbosity. This routine will eventually replace the old {\tt error.f } routine
inherited by \D while  {\tt e\_alloca} is specific for detecting
errors in the allocate procedure of F90 language.
The  {\tt error\_prot()} routine accepts 4 parameters ( the fourth is
optional) as specified in the following examples. If the code number is a
positive number the execution of the program will be stopped.  
Some examples read as follows:
\begin{verbatim}

TO CHANGE.. 

  call error_prot(subroutine_name,2400,  &
    'system too small for link-cell algorithm: use all-pairs', __LINE__)
 
  call error_prot(sub="your_routine", ierr=444, &
              message='other message goes here')

  allocate (myarray(max), stat=ierr)
  if (ierr/=0)  call e_alloca(sub=subname, &
                message='allocate stat code. Check user manual')

\end{verbatim}

Please use these subroutines quite extensively, except in the critical
parts where function-call overhead should be
minimized. (  \verb=__LINE__= is a  {\tt cpp}
intrinsic macro).


\section{Other Issues} 

\subsection{\fort/\oldfort\ (in)compatibility}

To achieve language compatibility the developer should keep in mind that
using arrays as dummy arguments can slow down the performances
dramatically. Beware of passing \fort\ array descriptors (e.g., {\tt
a(:,2:18:2)}) to \oldfort\ ssubroutines. This forces the \fort compiler to
make local copies of the array in order to make it contiguous, whereas in
\fort contiguity is not required with a net loss of speed.

\subsection{\fort/\C (in)compatibility}

C subroutines are called within \fort codes.  Underscores and
capital names should sometimes be added to the routine names to have
compatibility. The reader should read the compiler manual and undertake
proper action.
 

\subsection{\fort\ pitfalls}


\begin{description}
\item[pointers] \fort\ pointers are initially not defined. This causes
unpredictable results, e.g., when doing \verb=associated(p)=, where {\tt p}
is a pointer. Always \verb=nullify= the pointers first!

\item[derived data types] (related to above) As you can not place allocatable
arrays inside derived data types, they are necessarily
pointers. Whenever possible, {\tt nullify} them before they are
accessed.

\item[interfaces] External subroutines should usually be defined in an
interface in the appropriate module, to prevent problems with
\verb=intent= attributes, and with assumed-shaped arrays. E.g., see
{\tt SERIAL\_layer.F90}.

\item[array builtin subroutines] Beware of {\tt matmul} for large
matrices. The compiler allocates the result before copying to the
left-hand side ({\em aliasing} problem).

\item[interfaces] Several procedures that act on similar objects, are
usually interfaced to one generic subroutine name. One should be
careful not to forget to update all other similar routines, when one
of them is modified. E.g., {\tt gdsum\_} in {\tt MPI\_layer} is
written in four versions, for the different data types. The four
procedures are almost identical.

\item[creation and destruction] \fort\ has no object constructor or
destructor. Thus, one needs to write subroutines to allocate, define,
or initialize new objects. One can also overload the
assignment(=). Never forget to
destruct, when no longer needed!

\item[Intrinsic assignment] of derived data types is dangerous, when
the data type contains pointers. In fact, the intrinsic assignment
uses {\em pointer assignment} for pointer components!
 Use assignment {\em overloading}, to actually copy the data
\end{description}



\section{ Documentation ( i.e. how to document code) }

TO BE REARRANGED 



The \PR\ project has three different main sources for documentation: the
user guide and the present manual and a  self-documenting method based on
{\em f90doc version 0.2.5,} a documentation tool for Fortran 90. 
( see \verb=http://daisy.uwaterloo.ca/~eddemain/f90doc=. fo further information)
\verb=f90doc= is a perl script that reads each piece of code  
and produces nicely formatted html page about it. The documentation s 
produced can be found on the \PR web site.  In order to use \verb=f90doc=
at its best, developers should follow two simple rules:

\begin{itemize}
\item A header block of \fort comment records giving:
\begin{enumerate}
\item Name of the routine: 
\item The version number of the package
\item A brief description of the function of the subroutine/module
\item the three CVS macro: Author,Date and Revision  
\end{enumerate}
must precede the subroutine/module declaration as presented in the
following example:

\begin{verbatim}
!!>
!!c***********************************************************************
!!c   ROUTINE: PAIR_FORCE_PROT   
!!c   PACKAGE VERSION: DLPROTEIN-2.1
!!c   ACTION: controls calculation of pair interactions
!!c 
!!c       $Author: cozzini $
!!c       $Date: 2004-05-31 09:57:23 $
!!c       $Revision: 1.1.1.1 $
!!c
!!c***********************************************************************
!!<
SUBROUTINE pair_force_prot &
     (nstep,imcon,iregn,keyfce,mxregn, & ...
\end{verbatim}

\item The variables description must be placed after `` !!'' on the same line
of declaration. E.g.

\begin{verbatim}
 integer, intent(in) :: ilen    !! size of the neighbour list 
\end{verbatim}    


\end{itemize} 

\chapter{ Useful (?) Tips }
\section{How to debug the code }

\PR provides a Debugging facility to help developers and users.
In order to activate the debugging facility, the code must be compiled
with the macro \verb=DEBUG= enabled. 
At runtime the code produces different files containing information
about different processors. File names are \verb=DEBUG_0= for processors 0 
or for a serial run, and \verb=fort.={\it nn} for parallel runs, 
where {\it nn} is the processor number, numbered from 0 to N-1.

The debug level goes from 0 (very basic information) to 6 (detailed
information: beware the \verb=DEBUG_.={\it nn} files can be huge).

The default behaviour of the code is DEBUG enabled and debug\_level
variable equal to 1. DEBUG\_* files report quite detailed information about
the initialization phase and then silence during the iteration steps. 
We strongly recommend  users/developers to run with this default,
especially when they start to simulate new systems.
The debug\_level variable can also be set by a CONTROL directive of the
following kind: \verb=debug level 3=.\

\par
For developers it also possible to switch on/off the debug flag in specific
sections of the code. For this task two subroutines within  
\verb=service_module.F90= are provided : \verb=start_debug= 
and \verb=stop_debug=;

In the code all the debug section are inserted within
\begin{verbatim}
ifdef DEBUG
endif macro.
\end{verbatim}

It is a good idea when a new DEBUG section is placed in the code to
add a short comment about the information printed-out. 
Also in the service module there is a specific routine \verb=print_info=  to
print out information on the correct DEBUG file in case of parallel runs    
A typical debug examples could be of this kind:

\begin{verbatim}
#ifdef DEBUG
  !!debug_print_out:level5
  !!print out local values of virial for each molecule:
  if (ldebug.and.(debug_level.ge.5)) then 
     call write_info(subroutine_name,'molecule number',nm)
     call write_info(subroutine_name,'virial bonds',vir_bonds)
     call write_info(subroutine_name,'virial conic',vir_conic)
     call write_info(subroutine_name,'virial scalar',vir_scalar)
     call write_info(subroutine_name,'esig ',esig)
     call write_info(subroutine_name,'number_of_iterations',icyc)
  end if
#endif
\end{verbatim}

The \verb=write_info= routine has the following interface:
\begin{verbatim}

  INTERFACE WRITE_info
     MODULE PROCEDURE printa_i  !! write for integer datatype
     MODULE PROCEDURE printa_r  !! write for real datatype
  END INTERFACE
 ...
  SUBROUTINE printa_i(sub,variable,value,line)
    IMPLICIT NONE
    CHARACTER*(*), INTENT(in) :: sub      !!subroutine name ( callee)
    CHARACTER*(*), INTENT(in) :: variable !!a comment
    INTEGER, INTENT (in) :: value         !!an integer variable
    INTEGER, OPTIONAL, INTENT(in) :: line !! the line ( use _CPP_ )
      
\end{verbatim} 

It always useful during debugging sessions look at helpful options of the
compilers.


\section{How to measure performance and timing system }

The \PR\  code  has its own internal timing system that gives information
at the end the run. The code prints out in the OUTPUT file the Total time
per timestep together with the most consuming part.
These numbers are the data used to measure standard performances of the
code on different platforms \cite{performance}.

When the code is compiled with the DEBUG option enabled a precise and
detailed analysis is performed on all the most important routines: for each
of them the number of calls and the global time are reported. For parallel
execution the total time is the average time among processors: the highest
and the lowest time together with the number of processors are also
reported as in the following example:

It is recommended to use standard profiling tools ( prof/gprof ) to help
in optimizing the code as well. 


\section { How to add a new FFT routine} 
To be completed 

\section { How to port the code on a different architecture}

To be completed 
\chapter{ the \PR module hierarchy }

We describe the module hierarchy of the program. \PR is now organized in
several layer by means of \fort modules. A schematic depiction of the new
structure is presented below:   


\begin{verbatim}
       _________________________________________________________ 
      |                                                         |
      |   dlprotein2 / sloop / mloop routine                    |
      !---------------------------------------------------------|
      | spme_mod |                                              |
      |----------| <--- (class modules)                         |
      | fft_mod  |                                              |
      ! _________|______________________________________________| 
      | routines/ data modules        |                         | 
      | with comunication             |                         | 
      |-------------------------------|  routines/ data modules |
      | merge_mod | distribute_mod    | with no  comunication   | 
      |-------------------------------|                         |
      |         COMM_LAYER            |                         |
      |_______________________________|_________________________|
      |          basic modules:  service_mod                    !
      !                          allocator_mod/zeroing          |           
      |_________________________________________________________| 
\end{verbatim}

\section{ Basic modules }

Basic modules are modules used almost everywhere in the code: they offer
methods used in many other modules and routines. They generally have their
own private data and they just export public routines. They do not use any
other module. These modules could be easily integrated and used
also in different programs.
  
The basic modules are: 
\begin{description}
\item[ service\_module.F90] ``The basic module'': it provides all the timing
and debugging mechanism as explained before.  The error\_prot routine also
is within it. It has its own parallel routines for gather and scatter data
among processors when needed.  Each important routine/module should use it
to provide debugging and timing info.
 
\item[ zeroing\_mod.F90] a module that contains routines to zero initialize
 vectors.
\item[ allocator\_mod.F90] a module that contains allocate/dellacate
procedure for different data types ( 1-D/2-D real/integer arrays)
\item[ fft\_mod.F90] a module that contains specific implementations for
fft library.
\end{description}


\section { communication/parallel modules: }

Upon the basic modules a communication layer is placed: it takes care
to interface standard communication libraries with the code.
 
\begin{description}
\item[ COMM\_LAYER]
 This is actually a preprocessor MACRO. This is why it is written in
 capital letters. It will be replaced by the specific layer accordingly to
 the choice made in Makefile. This communication layer defines all basic
 communication operations used in the code and it
 is used by all the routines that need to communicate data among
 processors.
\item[ MPI\_layer]: the MPI implementation of the communication operations
needed by the program
\item[ SHMEM\_layer]: the SHMEM implementation of the communication operations
needed by the program: it should work on SGI machine. 
\item[ SERIAL\_layer]: a fake module where void routines are implemented in
order to maintain the same hierarchy of modules also in the serial
version. Please note that there is no overhead because this void routines
are never called in the serial version.
needed by the program

\item[ distribute\_mod]
 this module distributes atoms among processors and set integer arrays
 needed to compute the merge operation.

\item[ merge\_mod] 
 the module that containts the merge routines to merge coordinates among
 processors: it uses data defined in the distribute module. The merge
 operation is implemented using the appropriate communication library.  

\end{description}

\section{ Data Modules }

The third layer are mainly composed by data modules where data structures
scattered through the code are encapsulated.The list of these modules
is the following: ( to complete)

\begin{description}

\item[ atomic\_arrays.F90]
this module contains all the info for arrays of length equal to the 
number of atoms in the system.
It can be used by any module or subroutines that need this info..

\item[ non\_bonded\_mod.F90]
this module contains all the arrays and stuff for non-bonded  interactions

\item[ neigh\_lists.F90]
In this module are declared as ALLOCATABLE the neighbours lists and the 
corresponding lentry vectors 
 

\item[ excluded\_lists.F90]
	This module contains the
        arrays needed by excluded atoms namely: { \tt lexatm nexatm noxatm
        lexsit nexsit }

\end{description}


\section{ Class Modules }

These modules mimic a C++ class: data and procedure acting on them are all
stored together. Generally such a module solve a precise task by means of
public method. All the internal data should be declared as private in this
kind of modules.  Examples of class modules are:
\begin{description}

\item[ utailor\_mod] the module that takes care to sew the molecules at the
beginnig of the simulation. In this case the only external interface is the 
routine utailor 

\item[ spme\_mod] The module where electroctatic is computed by means of
SPME algorithms. The only public interfaces are the { \tt
set\_spme\_parameters }  and
{ \tt spme\_prot routines }; It uses  the {\tt fft\_mod } module to deal
with the fft libraries. 
 
\end{description}

\section{How to Design a module}

The main purpose of a module is one or more of the following:

\begin{itemize}
\item Define derived data types and operations thereof (objects and
methods). E.g., {\tt force\_field.F90}. (a class module)
\item Define global data, shared among different
subroutines/modules. E.g., {\tt atomic\_arrays.F90}. ( a data module)
\item provide interfaces to external subroutines. E.g., {\tt fft\_mod MPI\_layer}. 
\item provide a set of library-style subroutines. E.g., {\tt
allocator.F90}. (a basic module)
\end{itemize}

In general, these tasks should not be satisfied by one single module

To make a module accessible, write a {\tt use} statement. It is
usually a good idea to specify with {\tt only} the quantities needed,
in order to minimize overhead and prevent ambiguity. Example:
\begin{verbatim}
use ewald_module, only: alpha
\end{verbatim}
if only the alpha parameter is needed in a subroutine. Also, declare
as much as possible data to be private to the module. {\em Ideally, all
components of a data type object should be private}. For the sake of
efficiency, this is not always achieved in \PR.

Modules should be designed such as to make life easy for those who
will extend \PR.

% 
% #\subsection{Derived data types}
% #
% #There are two main considerations on how to design a new data type:
% #
% #\begin{itemize}
% #\item a collection of logically connected data, as in the {\tt
% #structure} of the \C language, or the common block in \oldfort. Such a
% #data type allows for a compact way of referring to a (large) set of
% #data. Example: none at the moment.
% 
% \item a true {\em object}, for which {\em methods} are provided,
% operators overloaded, etc. In \PR this kind of Derived data type is not
% really present at the moment.
% \end{itemize}
% 
% The advantages of derived data types are: their components can be
% changed, without having to change all the ``high-level'' code,
% functions and operators can be defined and modified without changing
% anything else, \PR\ flavors are coded on a very low level (e.g.,
% constraints  ``almost'' only in {\tt
% constraints\_mod} ), high-level code becomes
% very transparent, readable, and robust. 
% \
% \
% !
% 
% \subsection{Module procedures}
% 
% Having defined a new data type, one usually wants to add functions,
% subroutines, operators, etc. to act on the new object. All these
% procedures should be placed in the module, in order to share {\tt
% private} data, and to be available at the same place as the object
% (via ``use association''). One of the really painful shortcomings of
% \fort\ is the absence of inheritance. To make virtually the same task,
% one has to rewrite the same procedure for similar data types (see {\tt
% MPI\_layer}, where four field types are defined). In C++, {\tt
% MPI\_layer} would be about four times shorter 
% 
% At some point, you may wish to limit the size of a module, and place
% some procedures externally, even if they act on data types. This can
% be done, provided that no module-private data need to be accessed,
% and provided {\em that an interface be placed in the same, or another, module}.
% This method is actually widely used in \PR\ because of my lazyness to
% convert old \oldfort\ subroutines to new \fort\ code and include them in
% the appropriate module. 
% 
% 
% \subsection{Interfaces and overloading}
% 
% \fort\ interfaces are a powerful tool to reference several procedures
% by a single generic name, or to define and overload unary and binary
% operators, and even the assignment(=). Some caution is in order with
% operators of high rank which return large objects; the compiler may be
% forced to allocate an extra copy of the result on the stack before
% copying to the left-hand side.
%  For example, let's say you want to
% multiply two vectors, and you have defined a binary operator
% \verb=.times.= which is interfaced to a function that returns a vector,
% or a unary \verb=.fft.= that FFT's a vector. Then you can write very
% elegantly
% \begin{verbatim}
% f = f .times. g
% f = .fft. f
% \end{verbatim}
% The compiler make conservative assumptions about {\em aliasing} and
% side effects, and thus allocates a vector (the rhs) before copying to
% the left-hand side (which in this example is indeed aliased to data on
% the rhs). It is preferable to use BLAS-style subroutine calls in these
% cases:
% \begin{verbatim}
% call mult_vector(one,f,g,zero,f) ! f <- f*g + 0*f
% call cft(f,1)
% \end{verbatim}
% 
% This aliasing problem does not arise for operators whose rank is small, such as
% the linear algebra of 3D dimensional vectors.
% 
\section{External subroutines}

There are a certain number of self-consistent routines that do not share
any module. These will eventually disappear.



% \begin{description}
% \item[Interface:] always declare external subroutines in interfaces,
% usually placed in a module. Example: {\tt potential\_mod,
% energy\_mod}.
% 
% \end{description}
% 


